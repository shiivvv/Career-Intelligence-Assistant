# Career Intelligence Assistant - Environment Configuration

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
LLM_MODEL=llama3.2
EMBEDDINGS_MODEL=mxbai-embed-large

# Vector Store Configuration
PERSIST_DIR=./chroma_db
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# RAG Retrieval Configuration
NUM_RETRIEVED_DOCS=6
LLM_TEMPERATURE=0.1

# Streamlit Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
